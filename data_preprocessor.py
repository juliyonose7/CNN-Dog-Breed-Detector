"""
Preprocesador of data for classification binaria dog vs NO-dog
Optimized for training with GPU AMD 7900XTX
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.transforms import functional as F
import albumentations as A
from albumentations.pytorch import ToTensorV2
from sklearn.model_selection import train_test_split
import shutil
from tqdm import tqdm
import json
import random
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

class DogClassificationDataset(Dataset):
    """Dataset personalizado for classification binaria of dogs"""
    
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        label = self.labels[idx]
        
        # Load image
        try:
            image = cv2.imread(str(image_path))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"Error cargando imagen {image_path}: {e}")
            # Image of fallback
            image = np.zeros((224, 224, 3), dtype=np.uint8)
        
        if self.transform:
            transformed = self.transform(image=image)
            image = transformed['image']
        
        return image, torch.tensor(label, dtype=torch.float32)

class DataPreprocessor:
    """Preprocesador main for the dataset"""
    
    def __init__(self, dataset_path: str, output_path: str, target_size: tuple = (224, 224)):
        self.dataset_path = Path(dataset_path)
        self.output_path = Path(output_path)
        self.target_size = target_size
        self.yesdog_path = self.dataset_path / "YESDOG"
        self.nodog_path = self.dataset_path / "NODOG"
        
        # Create directory of output
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # Implementation note.
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        
        # Implementation note.
        self.imagenet_mean = [0.485, 0.456, 0.406]
        self.imagenet_std = [0.229, 0.224, 0.225]
        
    def collect_all_images(self):
        """Recolecta all the paths of images and labels"""
        print("ðŸ“‚ Recolectando rutas de imÃ¡genes...")
        
        image_paths = []
        labels = []
        
        # Images of dogs (label 1)
        print("   Procesando imÃ¡genes de perros...")
        dog_count = 0
        for breed_folder in tqdm(list(self.yesdog_path.iterdir())):
            if breed_folder.is_dir():
                for img_file in breed_folder.iterdir():
                    if img_file.suffix.lower() in self.image_extensions:
                        if self._is_valid_image(img_file):
                            image_paths.append(img_file)
                            labels.append(1)  # Dog
                            dog_count += 1
        
        # Images of no-dogs (label 0)
        print("   Procesando imÃ¡genes de no-perros...")
        nodog_count = 0
        for category_folder in tqdm(list(self.nodog_path.iterdir())):
            if category_folder.is_dir():
                for img_file in category_folder.iterdir():
                    if img_file.suffix.lower() in self.image_extensions:
                        if self._is_valid_image(img_file):
                            image_paths.append(img_file)
                            labels.append(0)  # No-dog
                            nodog_count += 1
        
        print(f"âœ… RecolecciÃ³n completada:")
        print(f"   - ImÃ¡genes de perros: {dog_count:,}")
        print(f"   - ImÃ¡genes de no-perros: {nodog_count:,}")
        print(f"   - Total: {len(image_paths):,}")
        print(f"   - Ratio perros/no-perros: {dog_count/max(nodog_count, 1):.2f}")
        
        return image_paths, labels
    
    def _is_valid_image(self, image_path: Path) -> bool:
        """Technical documentation in English."""
        try:
            img = cv2.imread(str(image_path))
            return img is not None and img.shape[0] > 0 and img.shape[1] > 0
        except:
            return False
    
    def balance_classes(self, image_paths: list, labels: list, strategy: str = 'undersample'):
        """Balancea the classes of the dataset"""
        print(f"âš–ï¸ Balanceando clases con estrategia: {strategy}")
        
        # Separar for classes
        dog_indices = [i for i, label in enumerate(labels) if label == 1]
        nodog_indices = [i for i, label in enumerate(labels) if label == 0]
        
        dog_count = len(dog_indices)
        nodog_count = len(nodog_indices)
        
        print(f"   Antes - Perros: {dog_count:,}, No-perros: {nodog_count:,}")
        
        if strategy == 'undersample':
            # Reducir the class mayoritaria
            target_size = min(dog_count, nodog_count)
            
            if dog_count > target_size:
                dog_indices = random.sample(dog_indices, target_size)
            if nodog_count > target_size:
                nodog_indices = random.sample(nodog_indices, target_size)
                
        elif strategy == 'oversample':
            # Aumentar the class minoritaria (duplicando images)
            target_size = max(dog_count, nodog_count)
            
            if dog_count < target_size:
                needed = target_size - dog_count
                dog_indices.extend(random.choices(dog_indices, k=needed))
            if nodog_count < target_size:
                needed = target_size - nodog_count
                nodog_indices.extend(random.choices(nodog_indices, k=needed))
        
        # Reconstruir listas balanceadas
        balanced_indices = dog_indices + nodog_indices
        balanced_paths = [image_paths[i] for i in balanced_indices]
        balanced_labels = [labels[i] for i in balanced_indices]
        
        # Mezclar
        combined = list(zip(balanced_paths, balanced_labels))
        random.shuffle(combined)
        balanced_paths, balanced_labels = zip(*combined)
        
        print(f"   DespuÃ©s - Perros: {balanced_labels.count(1):,}, No-perros: {balanced_labels.count(0):,}")
        
        return list(balanced_paths), list(balanced_labels)
    
    def create_train_val_test_split(self, image_paths: list, labels: list, 
                                  train_ratio: float = 0.7, val_ratio: float = 0.15):
        """Divide the dataset en train/validation/test"""
        print(f"ðŸ“Š Dividiendo dataset: train={train_ratio:.0%}, val={val_ratio:.0%}, test={1-train_ratio-val_ratio:.0%}")
        
        # Implementation note.
        train_paths, temp_paths, train_labels, temp_labels = train_test_split(
            image_paths, labels, test_size=(1-train_ratio), 
            random_state=42, stratify=labels
        )
        
        # Implementation note.
        val_size = val_ratio / (val_ratio + (1-train_ratio-val_ratio))
        val_paths, test_paths, val_labels, test_labels = train_test_split(
            temp_paths, temp_labels, test_size=(1-val_size),
            random_state=42, stratify=temp_labels
        )
        
        splits = {
            'train': {'paths': train_paths, 'labels': train_labels},
            'val': {'paths': val_paths, 'labels': val_labels},
            'test': {'paths': test_paths, 'labels': test_labels}
        }
        
        for split_name, split_data in splits.items():
            dog_count = split_data['labels'].count(1)
            nodog_count = split_data['labels'].count(0)
            total = len(split_data['labels'])
            print(f"   {split_name.upper():5s}: {total:5,} imÃ¡genes (perros: {dog_count:,}, no-perros: {nodog_count:,})")
        
        return splits
    
    def get_augmentation_transforms(self, mode: str = 'train'):
        """Technical documentation in English."""
        
        if mode == 'train':
            # Implementation note.
            transform = A.Compose([
                A.Resize(height=self.target_size[0], width=self.target_size[1]),
                A.HorizontalFlip(p=0.5),
                A.RandomRotate90(p=0.3),
                A.Rotate(limit=15, p=0.5),
                A.RandomBrightnessContrast(
                    brightness_limit=0.2, 
                    contrast_limit=0.2, 
                    p=0.5
                ),
                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
                A.RandomGamma(gamma_limit=(80, 120), p=0.3),
                A.HueSaturationValue(
                    hue_shift_limit=10,
                    sat_shift_limit=20,
                    val_shift_limit=20,
                    p=0.3
                ),
                A.RandomCrop(height=int(self.target_size[0]*0.9), 
                           width=int(self.target_size[1]*0.9), p=0.3),
                A.Resize(height=self.target_size[0], width=self.target_size[1]),
                A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.2),
                A.Normalize(mean=self.imagenet_mean, std=self.imagenet_std),
                ToTensorV2()
            ])
        else:
            # Implementation note.
            transform = A.Compose([
                A.Resize(height=self.target_size[0], width=self.target_size[1]),
                A.Normalize(mean=self.imagenet_mean, std=self.imagenet_std),
                ToTensorV2()
            ])
        
        return transform
    
    def create_data_loaders(self, splits: dict, batch_size: int = 32, num_workers: int = 4):
        """Creates the DataLoaders for training"""
        print(f"ðŸ”„ Creando DataLoaders (batch_size={batch_size}, num_workers={num_workers})...")
        
        # Transformaciones
        train_transform = self.get_augmentation_transforms('train')
        val_transform = self.get_augmentation_transforms('val')
        
        # Datasets
        train_dataset = DogClassificationDataset(
            splits['train']['paths'], 
            splits['train']['labels'], 
            transform=train_transform
        )
        
        val_dataset = DogClassificationDataset(
            splits['val']['paths'], 
            splits['val']['labels'], 
            transform=val_transform
        )
        
        test_dataset = DogClassificationDataset(
            splits['test']['paths'], 
            splits['test']['labels'], 
            transform=val_transform
        )
        
        # DataLoaders
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            num_workers=num_workers,
            pin_memory=True,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_dataset, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=num_workers,
            pin_memory=True
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=batch_size, 
            shuffle=False, 
            num_workers=num_workers,
            pin_memory=True
        )
        
        print(f"âœ… DataLoaders creados:")
        print(f"   - Train: {len(train_loader)} batches")
        print(f"   - Val:   {len(val_loader)} batches")
        print(f"   - Test:  {len(test_loader)} batches")
        
        return {
            'train': train_loader,
            'val': val_loader,
            'test': test_loader
        }
    
    def save_preprocessing_info(self, splits: dict):
        """Technical documentation in English."""
        info = {
            'dataset_stats': {
                'total_images': sum(len(split['labels']) for split in splits.values()),
                'train_images': len(splits['train']['labels']),
                'val_images': len(splits['val']['labels']),
                'test_images': len(splits['test']['labels']),
            },
            'class_distribution': {
                'train': {
                    'dogs': splits['train']['labels'].count(1),
                    'no_dogs': splits['train']['labels'].count(0)
                },
                'val': {
                    'dogs': splits['val']['labels'].count(1),
                    'no_dogs': splits['val']['labels'].count(0)
                },
                'test': {
                    'dogs': splits['test']['labels'].count(1),
                    'no_dogs': splits['test']['labels'].count(0)
                }
            },
            'preprocessing_config': {
                'target_size': self.target_size,
                'normalization_mean': self.imagenet_mean,
                'normalization_std': self.imagenet_std,
                'augmentation_enabled': True
            }
        }
        
        info_path = self.output_path / 'preprocessing_info.json'
        with open(info_path, 'w') as f:
            json.dump(info, f, indent=2)
        
        print(f"ðŸ’¾ InformaciÃ³n guardada en: {info_path}")
        
    def process_complete_dataset(self, balance_strategy: str = 'undersample', 
                               batch_size: int = 32):
        """Procesa the dataset complete"""
        print("ðŸš€ Iniciando preprocesamiento completo...")
        print("="*60)
        
        # 1. Recolectar images
        image_paths, labels = self.collect_all_images()
        
        # 2. Balancear classes
        if balance_strategy:
            image_paths, labels = self.balance_classes(image_paths, labels, balance_strategy)
        
        # 3. Dividir en train/val/test
        splits = self.create_train_val_test_split(image_paths, labels)
        
        # 4. Create DataLoaders
        data_loaders = self.create_data_loaders(splits, batch_size=batch_size)
        
        # Implementation note.
        self.save_preprocessing_info(splits)
        
        print("\nðŸŽ‰ Â¡Preprocesamiento completado exitosamente!")
        return data_loaders, splits

def create_sample_visualization(data_loaders, save_path: str):
    """Technical documentation in English."""
    import matplotlib.pyplot as plt
    
    print("ðŸ“¸ Creando visualizaciÃ³n de muestras...")
    
    # Get batch of training
    train_loader = data_loaders['train']
    batch_iter = iter(train_loader)
    images, labels = next(batch_iter)
    
    # Implementation note.
    mean = torch.tensor([0.485, 0.456, 0.406])
    std = torch.tensor([0.229, 0.224, 0.225])
    
    fig, axes = plt.subplots(4, 4, figsize=(12, 12))
    fig.suptitle('Muestras del Dataset con AugmentaciÃ³n', fontsize=16)
    
    for i in range(16):
        row = i // 4
        col = i % 4
        
        # Desnormalizar image
        img = images[i].clone()
        for t, m, s in zip(img, mean, std):
            t.mul_(s).add_(m)
        img = torch.clamp(img, 0, 1)
        
        # Convertir a numpy
        img_np = img.permute(1, 2, 0).numpy()
        
        # Show
        axes[row, col].imshow(img_np)
        label_text = "ðŸ• PERRO" if labels[i].item() == 1 else "ðŸ“¦ NO-PERRO"
        axes[row, col].set_title(label_text, fontsize=10)
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… VisualizaciÃ³n guardada en: {save_path}")

if __name__ == "__main__":
    # Configuration
    dataset_path = r"c:\Users\juliy\OneDrive\Escritorio\NOTDOG YESDOG\DATASETS"
    output_path = r"c:\Users\juliy\OneDrive\Escritorio\NOTDOG YESDOG\processed_data"
    
    # Create preprocesador
    preprocessor = DataPreprocessor(dataset_path, output_path)
    
    # Procesar dataset
    data_loaders, splits = preprocessor.process_complete_dataset(
        balance_strategy='undersample',  # 'undersample', 'oversample', or None
        batch_size=32
    )
    
    # Implementation note.
    sample_viz_path = Path(output_path) / 'sample_visualization.png'
    create_sample_visualization(data_loaders, str(sample_viz_path))